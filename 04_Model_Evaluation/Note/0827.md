# 오전

- ## 개인프로젝트2 피드백

# 오후

- 회귀모델 분류모델 평가지표

  - 오차확인지표
  - MSE : 제곱을 하면 그래프에서 실제 사각형이 그려짐.(지수그래프처럼 가중치가 커짐)
  - MAE : 절댓값 처리 -> 합치고 n으로 나눔 (잘안씀)
  - RMSE : MSE에 비해 오차가 작은편(실무에서 많이 이용)

    - 특성에 대한 추가 공부하기

  - 분류모델평가 지표
    - confusion matrix
      - 정확도 만으로 보기 힘들면 다른 지표도 같이 보기(precision, recall)
      - 위 지표들을 합치면 f1 점수
      - fallout = 1 - specificity

- 추천모델 평가지표

  - precision@k = 실제로 추천받은 아이템의 갯수 / 선호 아이템 갯수(k개)
  - recall@k = 실제 추천받은 아이템의 갯수 / 전체 선호하는 아이템
  - hit@k
  - AP@k
  - MAP@k
  - MRR = 선호아이템이 몇번째에 나타나는가

- 모델이 제대로 학습을 하는가

  - [과적합](https://aws.amazon.com/ko/what-is/overfitting/)

    - 과대적합

      - 감지하는 방법

        - k-폴드 교차검증

      - 방지하는 방법
        - 조기 중지
        - 프루닝 : 유의미한 feature은 뽑아내는 것
        - 정규화
        - 앙상블링
        - 데이터증가

    - 어느정도 과적합은 용인됨.(지피티에서 질문을 했을때 무엇을 도와주냐고 물어보는 것)

  - [교차검정](https://scikit-learn.org/stable/modules/cross_validation.html)

- 불균형데이터

  - 데이터가 많아서는 문제가 잘 안생김 => 적어서 생김
  - 데이터샘플링

    - 언더샘플링 : 가장 개수가 적은 클래스를 제외한 나머지 모든 클래스의 개수를 줄이는 과정
    - 오버샘플링 : 삭제하는 방법이 문제를 일으키면 사용하는 방법. 소수 클래스의 개수를 늘리는 과정
      - sampling_strategy
      - smote oversampling : 데이터의 분포를 확인해서 선을 그어 사이사이를 매꾸는 방법(분포를 유지)

  - 불균형데이터에 강한 모델을 사용
    - 캣부스터
    - 앙상블 모델
