{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4bb9d1f-8397-479e-99e0-23e27b54d84e",
   "metadata": {},
   "source": [
    "# Faiss를 이용한 문서 검색 시스템 만들기\n",
    "---\n",
    "[Faiss(Facebook AI Similarity Search)](https://faiss.ai/)란 데이터의 유사도 검색 및 벡터 클러스터링을 위한 라이브러리라고 합니다. 간단히 말해, 자연어 유사도를 기반으로 문서 검색을 구현할 수 있다는 말이지요. 유사도 검색이라고 하면, 예전에도 이와 같은 기능을 구현하는 라이브러리가 없었던건 아니지만, 파이스를 이용할 경우 성능이 제법 좋고, 옵션을 자유자재로 설정할 수 있기 때문에 문서 검색 시스템을 구현할 때 이만한 선택이 없어 보입니다.\n",
    "<p></p></br>\n",
    "\n",
    "## 프로그램 구성\n",
    "---\n",
    "이번에는 파이썬(Python)을 이용한 문서 검색 시스템을 만들어 보겠습니다, 구현 방법은 간단한데요, 원하는 문서를 읽은 뒤, 적당한 크기로 자르고 임베딩을 한 다음 Faiss 데이터베이스를 만들어 줍니다. 다음에는 자연어를 이용해 해당 DB를 쿼리하면 끝이지요.\n",
    "<p></p></br>\n",
    "\n",
    "이 프로그램을 만들기 위해서 파이썬은 기본이고, [🦜️🔗랭체인(Langchain)](https://python.langchain.com/v0.2/docs/introduction/) 커뮤니티와 파이스를 설치해 주셔야 합니다. 모두 pip 패키지 관리자를 이용해 설치할 수 있으며, 내 컴퓨터의 GPU 상태에 따라 `faiss-cpu` 또는 `faiss-gpu` 중 하나를 설치해 주시면 됩니다.\n",
    "<p></p></br>\n",
    "\n",
    "## 검색용 문서\n",
    "---\n",
    "이번 파이썬 문서 검색 시스템에서 검색 대상으로 삼을 문서는 mdn web docs에서 제공하는 [HTML 기본](https://developer.mozilla.org/ko/docs/Learn/Getting_started_with_the_web/HTML_basics) 한국어 문서입니다. [mdn 깃허브](https://github.com/mdn/translated-content/blob/main/files/ko/learn/getting_started_with_the_web/html_basics/index.md)에 방문하면 해당 문서를 마크다운 파일로 다운로드할 수 있는데, 저는 이 파일에서 별도 편집은 거치지 않고 그대로 이용했습니다.\n",
    "<p></p></br>\n",
    "\n",
    "이제, 이 문서를 300자 단위로 자르고, 임베딩을 통해 데이터를 벡터화한 다음 이를 Faiss 데이터베이스로 만드는 작업입니다. 아래 코드를 참고해 주세요.\n",
    "<p></p></br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e06f3be-2539-456f-95a6-50c332db52cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Package\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from IPython.display import display_markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6af4c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3577: LangChainDeprecationWarning: Default values for HuggingFaceBgeEmbeddings.model_name were deprecated in LangChain 0.2.5 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceBgeEmbeddings constructor instead.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Could not import sentence_transformers python package. Please install it with `pip install sentence_transformers`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\langchain_community\\embeddings\\huggingface.py:320\u001b[0m, in \u001b[0;36mHuggingFaceBgeEmbeddings.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\sentence_transformers\\__init__.py:10\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m export_dynamic_quantized_onnx_model, export_optimized_onnx_model\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[0;32m      5\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrossEncoder\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:20\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputExample\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceTransformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fullname, get_device_name, import_from_string\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdynamic_module_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_class_from_dynamic_module, get_relative_import_files\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_card\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformerModelCardData, generate_model_card\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimilarity_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimilarityFunction\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\sentence_transformers\\model_card.py:35\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_datasets_available():\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DatasetDict, IterableDataset, Value\n\u001b[0;32m     37\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\datasets\\__init__.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.19.1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_reader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReadInstruction\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\datasets\\arrow_dataset.py:60\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpa\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompute\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpc\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pyarrow\\__init__.py:65\u001b[0m\n\u001b[0;32m     64\u001b[0m _gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_lib\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _gc_enabled:\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing lib: 지정된 프로시저를 찾을 수 없습니다.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m HuggingFaceBgeEmbeddings()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\langchain_community\\embeddings\\huggingface.py:323\u001b[0m, in \u001b[0;36mHuggingFaceBgeEmbeddings.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m--> 323\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    324\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import sentence_transformers python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    325\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install sentence_transformers`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    326\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m sentence_transformers\u001b[38;5;241m.\u001b[39mSentenceTransformer(\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name, cache_folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_folder, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_kwargs\n\u001b[0;32m    330\u001b[0m )\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-zh\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name:\n",
      "\u001b[1;31mImportError\u001b[0m: Could not import sentence_transformers python package. Please install it with `pip install sentence_transformers`."
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceBgeEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd9edf27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 438, which is longer than the specified 300\n",
      "Created a chunk of size 1402, which is longer than the specified 300\n",
      "Created a chunk of size 330, which is longer than the specified 300\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "documents = TextLoader(\"./html_basics.md\", encoding=\"utf8\").load()\n",
    "\n",
    "# Text Split\n",
    "text_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# Create DB\n",
    "db = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48ce3ec-b952-46a3-a1b3-3d1db78be99c",
   "metadata": {},
   "source": [
    "<p></p></br>\n",
    "\n",
    "## Faiss 데이터 쿼리\n",
    "---\n",
    "이번에는 Faiss를 이용해 만든 데이터베이스를 쿼리해 보도록 하겠습니다. 해당 작업은 `FAISS.similarity_search()` 함수를 이용해서 수행할 수 있는데요, 이 때 쿼리 내용은 일반적인 자연어를 그대로 입력해 주시면 됩니다. 예를 들어, 해당 문서에서 HTML의 정의를 알고 싶다면 'HTML은 무엇일까' 라는 말을 적으면 되겠지요.\n",
    "<p></p></br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cb38e3f-bd77-48fc-b29f-2deb337d0613",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Query\n",
    "query = \"HTML은 무엇일까\"\n",
    "answer = db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0752468a-f81c-40ef-a0c4-d330c5e373da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "HTML은 콘텐츠의 구조를 정의하는 _마크업 언어_ 입니다. HTML은 콘텐츠의 서로 다른 부분들을 씌우거나 감싸서 다른 형식으로 보이게하거나 특정한 방식으로 동작하도록 하는 일련의 **{{Glossary(\"element\", \"요소\")}}** 로 이루어져 있습니다. {{Glossary(\"tag\", \"태그\")}}로 감싸는 것으로 단어나 이미지를 다른 어딘가로 하이퍼링크하거나 단어들을 이탤릭체로 표시하고 글씨체를 크게 또는 작게 만드는 등의 일을 할 수 있습니다. 아래에 나오는 줄의 내용과 같이 예를 들 수 있습니다."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_markdown(answer[0].page_content, raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508e2040-fa19-464b-89aa-bad939ce4e67",
   "metadata": {},
   "source": [
    "<p></p></br>\n",
    "\n",
    "## 쿼리 결과 유사도 확인하기\n",
    "---\n",
    "만약, 해당 쿼리 결과의 유사도가 궁금하거나, 2순위 이하의 결과가 궁금하다면 `FAISS.similarity_search_with_score()` 함수를 이용해 보시는걸 추천드립니다. 해당 결과는 유사도 점수를 기반으로 상위 몇 가지의 답변을 리스트로 리턴해 주기 때문에, 원하는 답변을 선택하거나 어느정도 이상의 유사도를 걸러내기 위해 추가 작업을 할 때 도움이 됩니다.\n",
    "<p></p></br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0c70a71-c141-48a3-9e93-69c23f20235e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='HTML은 콘텐츠의 구조를 정의하는 _마크업 언어_ 입니다. HTML은 콘텐츠의 서로 다른 부분들을 씌우거나 감싸서 다른 형식으로 보이게하거나 특정한 방식으로 동작하도록 하는 일련의 **{{Glossary(\"element\", \"요소\")}}** 로 이루어져 있습니다. {{Glossary(\"tag\", \"태그\")}}로 감싸는 것으로 단어나 이미지를 다른 어딘가로 하이퍼링크하거나 단어들을 이탤릭체로 표시하고 글씨체를 크게 또는 작게 만드는 등의 일을 할 수 있습니다. 아래에 나오는 줄의 내용과 같이 예를 들 수 있습니다.', metadata={'source': './html_basics.md'}),\n",
       "  0.16946973),\n",
       " (Document(page_content='여기서 우리는 HTML 맛보기를 하였습니다. 더 알아보기 위해, [HTML 배우기](/ko/docs/Learn/HTML) 페이지로 가보세요.\\n\\n{{PreviousMenuNext(\"Learn/Getting_started_with_the_web/Dealing_with_files\", \"Learn/Getting_started_with_the_web/CSS_basics\", \"Learn/Getting_started_with_the_web\")}}', metadata={'source': './html_basics.md'}),\n",
       "  0.1735438),\n",
       " (Document(page_content='많은 웹의 내용은 목록이기 때문에, HTML은 이것을 위한 특별한 요소를 가지고 있습니다. 목록을 나타내는 것은 항상 최소 두 개의 요소로 구성됩니다. 가장 일반적인 목록의 종류는 순서가 있는 것과 순서 없는 것이 있습니다.', metadata={'source': './html_basics.md'}),\n",
       "  0.17826173),\n",
       " (Document(page_content='### 문단\\n\\n위에서 설명했듯이, {{htmlelement(\"p\")}} 요소는 문자의 문단을 포함하기 위한 것입니다. 일반적인 문자 내용을 나타낼 때 많이 사용하게 될 것입니다.\\n\\n```html\\n<p>This is a single paragraph</p>\\n```', metadata={'source': './html_basics.md'}),\n",
       "  0.17929386)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.similarity_search_with_score(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
