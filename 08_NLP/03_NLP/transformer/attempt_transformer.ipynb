{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.17.0-cp39-cp39-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting tensorflow-intel==2.17.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.17.0-cp39-cp39-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading h5py-3.12.1-cp39-cp39-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp39-cp39-win_amd64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading protobuf-4.25.5-cp39-cp39-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading grpcio-1.66.2-cp39-cp39-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.2.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl.metadata (14 kB)\n",
      "Collecting numpy<2.0.0,>=1.23.5 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading numpy-1.26.4-cp39-cp39-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.9.2)\n",
      "Collecting namex (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading optree-0.13.0-cp39-cp39-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.8.30)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached werkzeug-3.0.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (8.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.20.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\desktop\\chunjae_edu\\.conda\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.17.0-cp39-cp39-win_amd64.whl (2.0 kB)\n",
      "Downloading tensorflow_intel-2.17.0-cp39-cp39-win_amd64.whl (385.0 MB)\n",
      "   ---------------------------------------- 0.0/385.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.9/385.0 MB 18.1 MB/s eta 0:00:22\n",
      "    --------------------------------------- 6.3/385.0 MB 16.8 MB/s eta 0:00:23\n",
      "   - -------------------------------------- 10.5/385.0 MB 17.7 MB/s eta 0:00:22\n",
      "   - -------------------------------------- 12.6/385.0 MB 17.5 MB/s eta 0:00:22\n",
      "   - -------------------------------------- 14.9/385.0 MB 14.9 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 18.9/385.0 MB 17.0 MB/s eta 0:00:22\n",
      "   -- ------------------------------------- 20.4/385.0 MB 14.2 MB/s eta 0:00:26\n",
      "   -- ------------------------------------- 23.3/385.0 MB 14.8 MB/s eta 0:00:25\n",
      "   ---- ----------------------------------- 39.6/385.0 MB 21.3 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 46.7/385.0 MB 22.7 MB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 52.4/385.0 MB 23.7 MB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 54.8/385.0 MB 22.7 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 61.9/385.0 MB 24.0 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 62.7/385.0 MB 21.9 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 85.2/385.0 MB 27.7 MB/s eta 0:00:11\n",
      "   ---------- ---------------------------- 102.0/385.0 MB 31.3 MB/s eta 0:00:10\n",
      "   ----------- --------------------------- 112.2/385.0 MB 32.9 MB/s eta 0:00:09\n",
      "   ----------- --------------------------- 113.0/385.0 MB 30.7 MB/s eta 0:00:09\n",
      "   ----------- --------------------------- 113.5/385.0 MB 29.5 MB/s eta 0:00:10\n",
      "   ------------ -------------------------- 121.9/385.0 MB 29.8 MB/s eta 0:00:09\n",
      "   ------------ -------------------------- 125.3/385.0 MB 29.1 MB/s eta 0:00:09\n",
      "   -------------- ------------------------ 139.5/385.0 MB 31.1 MB/s eta 0:00:08\n",
      "   --------------- ----------------------- 154.1/385.0 MB 32.8 MB/s eta 0:00:08\n",
      "   --------------- ----------------------- 154.7/385.0 MB 31.5 MB/s eta 0:00:08\n",
      "   --------------- ----------------------- 157.8/385.0 MB 30.9 MB/s eta 0:00:08\n",
      "   ---------------- ---------------------- 163.1/385.0 MB 30.6 MB/s eta 0:00:08\n",
      "   ----------------- --------------------- 172.2/385.0 MB 31.0 MB/s eta 0:00:07\n",
      "   ----------------- --------------------- 173.8/385.0 MB 30.3 MB/s eta 0:00:07\n",
      "   ----------------- --------------------- 174.3/385.0 MB 29.4 MB/s eta 0:00:08\n",
      "   ------------------ -------------------- 178.3/385.0 MB 28.8 MB/s eta 0:00:08\n",
      "   ------------------- ------------------- 189.5/385.0 MB 29.6 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 204.2/385.0 MB 30.9 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 212.3/385.0 MB 31.2 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 222.8/385.0 MB 31.7 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 240.1/385.0 MB 33.4 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 251.1/385.0 MB 33.7 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 259.3/385.0 MB 34.1 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 270.8/385.0 MB 35.8 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 287.8/385.0 MB 41.2 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 300.7/385.0 MB 40.5 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 315.1/385.0 MB 42.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 322.7/385.0 MB 42.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 342.9/385.0 MB 44.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 351.8/385.0 MB 43.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 372.0/385.0 MB 44.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  384.8/385.0 MB 48.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  384.8/385.0 MB 48.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  384.8/385.0 MB 48.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  384.8/385.0 MB 48.6 MB/s eta 0:00:01\n",
      "   --------------------------------------- 385.0/385.0 MB 43.5 MB/s eta 0:00:00\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.66.2-cp39-cp39-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.3/4.3 MB 32.2 MB/s eta 0:00:00\n",
      "Downloading h5py-3.12.1-cp39-cp39-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.0/3.0 MB 88.3 MB/s eta 0:00:00\n",
      "Downloading keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 58.1 MB/s eta 0:00:00\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Downloading ml_dtypes-0.4.1-cp39-cp39-win_amd64.whl (126 kB)\n",
      "Downloading numpy-1.26.4-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 10.0/15.8 MB 47.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 49.7 MB/s eta 0:00:00\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-4.25.5-cp39-cp39-win_amd64.whl (413 kB)\n",
      "Using cached tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "Downloading tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 76.5 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached werkzeug-3.0.4-py3-none-any.whl (227 kB)\n",
      "Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.0-cp39-cp39-win_amd64.whl (270 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, numpy, grpcio, google-pasta, gast, astunparse, absl-py, ml-dtypes, markdown, h5py, tensorboard, keras, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.66.2 h5py-3.12.1 keras-3.6.0 libclang-18.1.1 markdown-3.7 ml-dtypes-0.4.1 namex-0.0.8 numpy-1.26.4 opt-einsum-3.4.0 optree-0.13.0 protobuf-4.25.5 tensorboard-2.17.1 tensorboard-data-server-0.7.2 tensorflow-2.17.0 tensorflow-intel-2.17.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.5.0 werkzeug-3.0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "blis 1.0.1 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
      "thinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "\n",
    "# * 파이토치 설치: ``\n",
    "# * 텐서플로우 설치: `!pip install tensorflow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\user\\Desktop\\Chunjae_edu\\.conda\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\Chunjae_edu\\.conda\\lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# sentiment analysis의 기본 모델: distilbert/distilbert-base-uncased-finetuned-sst-2-english\n",
    "classifier = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\Chunjae_edu\\.conda\\lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user\\.cache\\huggingface\\hub\\models--cardiffnlp--twitter-roberta-base-sentiment-latest. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-classification\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9989239573478699}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\n",
    "    \"Anakin Skywalker killed the Emperor and finally brought balance to the Force.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'neutral', 'score': 0.66680508852005}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"Anakin Skywalker killed the Emperor and finally brought balance to the Force.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
