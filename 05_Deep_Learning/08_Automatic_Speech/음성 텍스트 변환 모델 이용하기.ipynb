{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e76c47b5-6793-4894-963b-a15942323834",
   "metadata": {},
   "source": [
    "# 음성 텍스트 변환 모델 알아보기 (Automatic Speech Recognition)\n",
    "---\n",
    "딥러닝 기술 중 상업적으로 자주 사용되는 모델은 대표적으로 음성 인식 모델을 꼽을 수 있습니다. 음성 인식 모델, 혹은 음성 텍스트 변환 모델이라고 부르는 Automatic Speech Recognition(ASR)은 옛날에는 Speech to Text라는 이름으로 알려졌던 모델입니다. 이 모델은 우리가 일상생활에서 말하는 ARS, 홈쇼핑 전화의 주소 인식 모델, 장애인을 위한 자동 자막 생성 기술 등 여러 분야에서 이미 활용되고 있지요. 이번에는 OpenAI에서 제작한 whisper 모델을 활용해 파이썬으로 음성 텍스트 변환 프로그램을 구현해 보도록 하겠습니다.\n",
    "</p></br></br>\n",
    "\n",
    "## OpenAI whisper\n",
    "---\n",
    "whisper 모델은 대표적인 ASR 모델입니다. 영어뿐만 아니라 다양한 언어를 지원하며, 인식 성능도 상당한 수준이기 때문에 손쉽게 자연어 처리를 할 수 있다는 장점이 있지요. 게다가 음성 인식 모델을 활용할 시스템에 따라 tiny, small, medium, large, large-v2 모델을 취사선택할 수 있다는 점도 돋보입니다. 이번에는 그 중에서 [whisper-tiny](https://huggingface.co/openai/whisper-tiny) 모델과 [whisper-small](https://huggingface.co/openai/whisper-small) 모델을 서로 비교해보는 작업을 해 보겠습니다. 이 모델들은 모두 Huggingface에서 조회할 수 있으며, `transformers` 라이브러리에서 지원하는 `pipeline` 기능을 활용해 기능을 활용할 수 있습니다.\n",
    "</p></br></br>\n",
    "\n",
    "이 기능은 transformers 4.35.0 버전 및 ffmpeg가 설치된 환경, 그리고 인식할 오디오 파일을 요구합니다. ffmpeg 설치는 운영체제별로 지원되는 패키지 관리자에서 설치할 수 있으며, 윈도우의 경우 [chocolatey](https://chocolatey.org/)를 활용해 `choco install ffmpeg` 명령어를 실행하면 됩니다. 오디오 파일의 경우, mp3 및 flac 확장자 등을 지원합니다.\n",
    "</p></br></br>\n",
    "\n",
    "## 음성 인식 실습\n",
    "---\n",
    "저는 TEDxYouth@MCH에서 찾아볼 수 있는 [한국의 툰베리를 만나러 가는 길](https://www.ted.com/talks/chaeeun_kim?language=ko)의 음성 파일을 인식할 수 있도록 whisper 모델을 이용해 봤습니다. transformers에서 제공하는 pipeline 기능을 활용해서 한줄로 구현할 수 있지요. 아래 코드를 참조해 보시기 바랍니다.\n",
    "</p></br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fe53bf3-1497-40bc-9ea4-b71edca27c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f929bc9bc2d4057aef3f4649e3354a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.98k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user\\.cache\\huggingface\\hub\\models--openai--whisper-tiny. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\user\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f962f361a7d4385b5f90e827d1723ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd29686c43341199183607f5abaa492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/3.75k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eb10b5203e2454c9ed915bc0156d887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a76f2120d0494e8aacf59695967a4baf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/836k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab0e58f7b224080a14230feb5e6f0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5083e52e18de42d8aacaaf16b749c33d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c87d601a70445ba048c597bb853e33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ec23abdbc0549fa834ee60595ad2105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d626dadc7d45fa9dc2f275bcd154ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95fb7bd42f914bc6aa5748abbb894951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82ecba14ce7c49739b77906318bede70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.97k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user\\.cache\\huggingface\\hub\\models--openai--whisper-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba640b942d8f44e3a295b47f57ab6867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d527379115574a4d93f7c3e54e06f0b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/3.87k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ded2b4fb7d44acbc64badbf54ff546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "896e9cc09edd4b4fbd89aab3f98081a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/836k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0613131f6b3445cc9d52a79f156d6173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61494357570c46ea91b522478a8e3534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c31e129196794e7ebd5e5cf1fdcc32e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16da42eac531403893225a197397581e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15336cc9df764cf8a3c72f5e516b28f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39971e917b6486eb550eabcaf6fa0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import Package\n",
    "from transformers import pipeline\n",
    "\n",
    "# Import whisper model\n",
    "whisper_tiny = pipeline(\"automatic-speech-recognition\", \"openai/whisper-tiny\")\n",
    "whisper_small = pipeline(\"automatic-speech-recognition\", \"openai/whisper-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6679c52f-d89c-45ad-8990-f0b433f46368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ' 공굴 수 있는 미래를 위한 우리들의 외침 지금부터 시작하겠습니다 여러분 초콜라 좋아하세요 그럼 포동화 차리는요? 네 저는 전부 좋아하는 음식들인데요 특히 제가 초콜라에서 너무 너무 좋아해서 항상 가방 어딘가에 챙겨 놓을 정도입니다 그런데 이 음식들이 조만간 쉽게 먹을 수 없는 사체품이 된다고 합니다'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whisper_tiny(\n",
    "    \"https://github.com/boringariel/python/raw/tmp/audio/data/%ED%95%9C%EA%B5%AD%EC%9D%98%20%ED%88%B0%EB%B2%A0%EB%A6%AC%EB%A5%BC%20%EB%A7%8C%EB%82%98%EB%9F%AC%20%EA%B0%80%EB%8A%94%20%EA%B8%B8%20%20Chaeeun%20Kim%20%20TEDxYouthMCH.mp3\",\n",
    "    generate_kwargs={\"language\": \"korean\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a957f5d9-0bce-4173-b9f2-89ba7a64114f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ' 꿈꿀 수 있는 미래를 위한 우리들의 외침 지금부터 시작하겠습니다 여러분 초콜릿 좋아하세요? 네 그럼 포도나 체리는요? 아니요 네 저는 전부 좋아하는 음식들인데요 특히 제가 초콜릿을 너무너무 좋아해서 항상 가방 어딘가에 챙겨놓을 정도입니다 그런데 이 음식들이 조만간 쉽게 먹을 수 없는 사채품이 된다고 합니다'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whisper_small(\n",
    "    \"https://github.com/boringariel/python/raw/tmp/audio/data/%ED%95%9C%EA%B5%AD%EC%9D%98%20%ED%88%B0%EB%B2%A0%EB%A6%AC%EB%A5%BC%20%EB%A7%8C%EB%82%98%EB%9F%AC%20%EA%B0%80%EB%8A%94%20%EA%B8%B8%20%20Chaeeun%20Kim%20%20TEDxYouthMCH.mp3\",\n",
    "    generate_kwargs={\"language\": \"korean\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15a08b9-ea25-4b9d-b5ad-deb213a039fe",
   "metadata": {},
   "source": [
    "</p></br></br>\n",
    "\n",
    "음성 인식 결과물은 딕셔너리 형태로 반환되는데, 여기에서 text 라는 인덱스에 인식한 음성 정보가 입력됩니다. whisper-tiny 모델의 경우, 대충 알아들을 수 있을 정도지만 연음 처리가 어색한 부분이 보이네요. 예를 들어, '꿈꿀 수 있는 미래' 라는 말을 '공굴 수 있는 미래' 라고 읽는 등의 문제가 보입니다.\n",
    "</p></br></br>\n",
    "반면에 whisper-small 모델의 경우, 이정도면 쓸만하다고 생각될 만큼 처리 품질이 개선된 것을 확인할 수 있습니다. 앞서 살펴본 tiny 모델이 약했던 연음 처리도 자연스러워져서, '꿈꿀 수 있는 미래' 라는 말도 정확하게 읽어들였지요. medium 이상의 모델에서는 성능이 더욱 나아지지만, 시스템 요구사양 및 처리 속도에서 불리하기 때문에 사용 환경에 따라 적합한 사이즈의 모델을 선택해야 합니다.\n",
    "</p></br></br>\n",
    "\n",
    "## 프로그램 개선\n",
    "---\n",
    "whisper 모델을 그냥 사용할 경우, 최대 30초 분량의 음성만 인식할 수 있습니다. 그래서, 더욱 긴 분량의 음성을 인식하기 위해서는 30초 단위로 파일을 자른 뒤, 각각의 파일을 읽는 방법 등을 활용해야겠지요."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
