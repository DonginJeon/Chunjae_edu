{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import os, cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Sequential name=sequential, built=True>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\n",
    "    \"C:/Users/user/Desktop/models/resnet50_transfer_learning_model2.keras\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2890 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리 (ImageDataGenerator 사용)\n",
    "# train_datagen = ImageDataGenerator(rescale=1./255,  # 정규화\n",
    "#                                    shear_range=0.2,\n",
    "#                                    zoom_range=0.2,\n",
    "#                                    horizontal_flip=True)\n",
    "\n",
    "img_size = (300, 300)\n",
    "batch_size = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1.0 / 255, horizontal_flip=True)  # 정규화\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "# 훈련 데이터 및 검증 데이터 설정 (경로를 자신의 데이터셋에 맞게 설정하세요)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"./dataset/train_added/\",\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\",\n",
    ")  # 이진 분류\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    \"./dataset/validation/\",\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\",\n",
    ")  # 이진 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 990ms/step - accuracy: 1.0000 - loss: 1.1325e-05\n",
      "test loss, test acc: [1.2633096957870293e-05, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# 모델 검증\n",
    "results = model.evaluate(validation_generator)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['horse (1).jpg', 'horse (1).png', 'horse (10).jpg', 'horse (11).jpg', 'horse (12).jpg', 'horse (13).jpg', 'horse (14).jpg', 'horse (15).jpg', 'horse (16).jpg', 'horse (17).jpg', 'horse (18).jpg', 'horse (19).jpg', 'horse (2).jpg', 'horse (2).png', 'horse (20).jpg', 'horse (21).jpg', 'horse (22).jpg', 'horse (23).jpg', 'horse (24).jpg', 'horse (25).jpg', 'horse (26).jpg', 'horse (27).jpg', 'horse (28).jpg', 'horse (29).jpg', 'horse (3).jpg', 'horse (3).png', 'horse (30).jpg', 'horse (31).jpg', 'horse (32).jpg', 'horse (33).jpg', 'horse (34).jpg', 'horse (35).jpg', 'horse (36).jpg', 'horse (37).jpg', 'horse (38).jpg', 'horse (39).jpg', 'horse (4).jpg', 'horse (4).png', 'horse (40).jpg', 'horse (41).jpg', 'horse (42).jpg', 'horse (43).jpg', 'horse (44).jpg', 'horse (45).jpg', 'horse (46).jpg', 'horse (47).jpg', 'horse (48).jpg', 'horse (49).jpg', 'horse (5).jpg', 'horse (50).jpg', 'horse (51).jpg', 'horse (52).jpg', 'horse (53).jpg', 'horse (54).jpg', 'horse (55).jpg', 'horse (56).jpg', 'horse (57).jpg', 'horse (58).jpg', 'horse (59).jpg', 'horse (6).jpg', 'horse (60).jpg', 'horse (61).jpg', 'horse (62).jpg', 'horse (63).jpg', 'horse (64).jpg', 'horse (65).jpg', 'horse (66).jpg', 'horse (67).jpg', 'horse (68).jpg', 'horse (69).jpg', 'horse (7).jpg', 'horse (70).jpg', 'horse (71).jpg', 'horse (72).jpg', 'horse (73).jpg', 'horse (74).jpg', 'horse (75).jpg', 'horse (76).jpg', 'horse (77).jpg', 'horse (78).jpg', 'horse (79).jpg', 'horse (8).jpg', 'horse (80).jpg', 'horse (81).jpg', 'horse (82).jpg', 'horse (83).jpg', 'horse (84).jpg', 'horse (85).jpg', 'horse (86).jpg', 'horse (87).jpg', 'horse (88).jpg', 'horse (89).jpg', 'horse (9).jpg', 'horse (90).jpg', 'horse (91).jpg', 'horse (92).jpg', 'horse (93).jpg', 'horse (94).jpg', 'horse (95).jpg', 'horse (96).jpg', 'human (1).jpg', 'human (1).png', 'human (10).jpg', 'human (10).png', 'human (11).jpg', 'human (11).png', 'human (12).jpg', 'human (12).png', 'human (13).jpg', 'human (13).png', 'human (14).jpg', 'human (14).png', 'human (15).jpg', 'human (15).png', 'human (16).jpg', 'human (16).png', 'human (17).jpg', 'human (17).png', 'human (18).jpg', 'human (18).png', 'human (19).jpg', 'human (2).jpg', 'human (2).png', 'human (20).jpg', 'human (21).jpg', 'human (22).jpg', 'human (23).jpg', 'human (24).jpg', 'human (25).jpg', 'human (26).jpg', 'human (27).jpg', 'human (28).jpg', 'human (29).jpg', 'human (3).jpg', 'human (3).png', 'human (30).jpg', 'human (31).jpg', 'human (32).jpg', 'human (33).jpg', 'human (34).jpg', 'human (35).jpg', 'human (36).jpg', 'human (37).jpg', 'human (38).jpg', 'human (39).jpg', 'human (4).jpg', 'human (4).png', 'human (40).jpg', 'human (41).jpg', 'human (42).jpg', 'human (43).jpg', 'human (44).jpg', 'human (45).jpg', 'human (46).jpg', 'human (47).jpg', 'human (48).jpg', 'human (49).jpg', 'human (5).jpg', 'human (5).png', 'human (50).jpg', 'human (51).jpg', 'human (52).jpg', 'human (53).jpg', 'human (54).jpg', 'human (55).jpg', 'human (56).jpg', 'human (57).jpg', 'human (58).jpg', 'human (59).jpg', 'human (6).jpg', 'human (6).png', 'human (60).jpg', 'human (61).jpg', 'human (62).jpg', 'human (63).jpg', 'human (64).jpg', 'human (65).jpg', 'human (66).jpg', 'human (67).jpg', 'human (68).jpg', 'human (69).jpg', 'human (7).jpg', 'human (7).png', 'human (70).jpg', 'human (71).jpg', 'human (72).jpg', 'human (73).jpg', 'human (74).jpg', 'human (75).jpg', 'human (76).jpg', 'human (77).jpg', 'human (78).jpg', 'human (79).jpg', 'human (8).jpg', 'human (8).png', 'human (80).jpg', 'human (81).jpg', 'human (82).jpg', 'human (9).jpg', 'human (9).png']\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step  \n",
      "[[False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n"
     ]
    }
   ],
   "source": [
    "# 이미지 전처리\n",
    "dlist = \"./dataset/test/\"\n",
    "predict_list = os.listdir(dlist)\n",
    "print(predict_list)\n",
    "\n",
    "img = [cv2.imread(dlist + i) for i in predict_list]\n",
    "img = [cv2.resize(i, (300, 300)) for i in img]\n",
    "img = np.array(img)\n",
    "img = img.astype(\"float32\") / 255.0\n",
    "\n",
    "# 분류\n",
    "cutoff = 0.5\n",
    "predictions = model.predict(img)\n",
    "print(predictions >= cutoff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
