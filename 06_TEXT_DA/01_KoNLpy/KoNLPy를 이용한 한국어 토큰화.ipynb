{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc9d7f87-dd5f-42c3-831c-4144927fc1ef",
   "metadata": {},
   "source": [
    "# KoNLPy를 이용한 한국어 토큰화\n",
    "---\n",
    "\n",
    "## 자연어 처리\n",
    "---\n",
    "자연어 처리(NLP, Natural Language Processing)는 컴퓨터가 인간의 언어를 이해, 생성, 조작할 수 있도록 해주는 인공지능(AI)의 한 분야로 정의되어 있습니다. 만약 자연어 처리를 능수능란하게 할 수 있다면, 인터넷에서 흔히 구할 수 있는 문서 데이터를 모두 데이터 분석에 활용할 수 있기 때문에 활용도 또한 높지요.\n",
    "</p></br></br>\n",
    "\n",
    "파이썬(Python)에는 다양한 자연어 처리 패키지가 있습니다. 다만, 그 다수는 영어 기반인데요, 한국어 자연어 분석을 하기 위해서는 [코엔엘파이(KoNLPy)](https://konlpy.org/ko/latest/index.html)와 같은 전용 패키지를 이용할 필요가 있습니다. 코엔엘파이는 자바를 이용하는 패키지이기 때문에 공식 홈페이지의 설치 안내에 따라, JDK를 설치 후 이용해 주시기 바랍니다.\n",
    "</p></br></br>\n",
    "\n",
    "## 한국어 데이터의 토큰화\n",
    "---\n",
    "자연어 데이터는 입력된 그대로 분석하기에는 활용(活用, conjugation)이나 조사 등의 문제가 있습니다. 이에 따라, 규격화된 토큰(Token)으로 자연어 데이터를 분리하기 위해 자연어 처리 패키지는 토큰화(Tokenization)라는 작업을 요구합니다. 이번에는 KoNLPy의 Okt를 이용해 토큰화하는 예시를 보여드리겠습니다.\n",
    "</p></br></br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83156729-2a0d-4b3e-97a0-f92517b41ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['오', ',', '그녀', '는', '정말', '횃불', '에게', '찬란히', '타오르는', '법', '을', '가르치', '누나', '!', '그녀', '가', '밤', '의', '뺨', '에', '걸려', '있는', '모양', '이', ',', '에티오피아', '여인', '귀', '에', '걸린', '화려한', '보석', '같아', '.']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "\n",
    "tokenizer = Okt()\n",
    "\n",
    "\n",
    "\n",
    "sample_text = \"오, 그녀는 정말 횃불에게 찬란히 타오르는 법을 가르치누나! 그녀가 밤의 뺨에 걸려 있는 모양이, 에티오피아 여인 귀에 걸린 화려한 보석 같아.\"\n",
    "\n",
    "\n",
    "\n",
    "print(tokenizer.morphs(sample_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a894e0-247e-4f99-a9b3-2796c6ded58f",
   "metadata": {},
   "source": [
    "</p></br></br>\n",
    "\n",
    "위와 같은 코드를 실행하면, `sample_text` 가 단어의 뜻에 따라 분리되는 것을 볼 수 있습니다. Okt 토크나이저(Tokenizer)에서 분리하는 기준은 단어의 의미를 나타내는 단위인 형태소인데요, 토크나이저의 종류(Kkma, Hannanum, Komoran, Okt 등)에 따라 우리가 학교에서 배운 형태소의 기준과는 약간 다를 수 있으니 참고해 주시기 바랍니다.\n",
    "</p></br></br>\n",
    "\n",
    "## 문장부호 등을 삭제하는 방법\n",
    "---\n",
    "그런데, 이렇게 토큰화를 하는건 대개 자연어의 의미를 분석하기 위한 목적일겁니다. 이 때는 특별한 의미가 없는 각종 문장부호나 외국어 등을 삭제해야 하는데요, 다양한 방법이 있지만 `re` 패키지를 이용해서 한국어를 제외한 모든 데이터를 삭제하는게 편리합니다. 또는, 아래에서 살펴볼 토큰의 품사 태깅을 통해 필요한 요소만 선택하는 방법도 있지요.\n",
    "</p></br></br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ae1e0e7-ead2-458a-a7e9-94c273c656cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['오', '그녀', '는', '정말', '횃불', '에게', '찬란히', '타오르는', '법', '을', '가르치', '누나', '그녀', '가', '밤', '의', '뺨', '에', '걸려', '있는', '모양', '이', '에티오피아', '여인', '귀', '에', '걸린', '화려한', '보석', '같아']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "sample_text_2 = re.sub(\"[^가-힣 ]+\", \"\", sample_text)\n",
    "\n",
    "print(tokenizer.morphs(sample_text_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024eef02-b054-4c03-900b-3437816518fd",
   "metadata": {},
   "source": [
    "</p></br></br>\n",
    "\n",
    "## 단어의 품사 알아보기\n",
    "---\n",
    "자연어 데이터를 분석할 때, 품사에 따라 분석에 이용하거나 이용하지 않을 수 있습니다. 이를 위해서는 자연어 토큰화를 한 다음 각 토큰의 품사(POS, part-of-speech)를 알아봐야 하는데요, KoNLPy에서는 각 토크나이저에서 `pos` 라는 함수를 통해 품사 정보를 제시해 주고 있습니다. 지원하는 품사 정보는 [Korean POS tags comparison chart](https://docs.google.com/spreadsheets/d/1OGAjUvalBuX-oZvZ_-9tEfYD2gQe7hTGsgUpiiBSXI8/edit?gid=0#gid=0) 를 참조하거나, `tagset` 함수를 이용해 주세요. Okt 토크나이저는 Twitter라는 이름으로 작성되어 있습니다.\n",
    "</p></br></br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b95bf469-5957-4147-aaad-f674269dd5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('오', 'Noun'),\n",
       " ('그녀', 'Noun'),\n",
       " ('는', 'Josa'),\n",
       " ('정말', 'Noun'),\n",
       " ('횃불', 'Noun'),\n",
       " ('에게', 'Josa'),\n",
       " ('찬란히', 'Adjective'),\n",
       " ('타오르는', 'Verb'),\n",
       " ('법', 'Noun'),\n",
       " ('을', 'Josa'),\n",
       " ('가르치', 'Verb'),\n",
       " ('누나', 'Noun'),\n",
       " ('그녀', 'Noun'),\n",
       " ('가', 'Josa'),\n",
       " ('밤', 'Noun'),\n",
       " ('의', 'Josa'),\n",
       " ('뺨', 'Noun'),\n",
       " ('에', 'Josa'),\n",
       " ('걸려', 'Verb'),\n",
       " ('있는', 'Adjective'),\n",
       " ('모양', 'Noun'),\n",
       " ('이', 'Josa'),\n",
       " ('에티오피아', 'Noun'),\n",
       " ('여인', 'Noun'),\n",
       " ('귀', 'Noun'),\n",
       " ('에', 'Josa'),\n",
       " ('걸린', 'Verb'),\n",
       " ('화려한', 'Adjective'),\n",
       " ('보석', 'Noun'),\n",
       " ('같아', 'Adjective')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pos(sample_text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ca0b6d4-b7b7-4e76-a984-6048084e2f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Adjective': '형용사',\n",
       " 'Adverb': '부사',\n",
       " 'Alpha': '알파벳',\n",
       " 'Conjunction': '접속사',\n",
       " 'Determiner': '관형사',\n",
       " 'Eomi': '어미',\n",
       " 'Exclamation': '감탄사',\n",
       " 'Foreign': '외국어, 한자 및 기타기호',\n",
       " 'Hashtag': '트위터 해쉬태그',\n",
       " 'Josa': '조사',\n",
       " 'KoreanParticle': '(ex: ㅋㅋ)',\n",
       " 'Noun': '명사',\n",
       " 'Number': '숫자',\n",
       " 'PreEomi': '선어말어미',\n",
       " 'Punctuation': '구두점',\n",
       " 'ScreenName': '트위터 아이디',\n",
       " 'Suffix': '접미사',\n",
       " 'Unknown': '미등록어',\n",
       " 'Verb': '동사'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tagset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
